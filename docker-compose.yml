services:
  # Neo4j Graph Database
  neo4j:
    image: neo4j:5.15
    container_name: autodocs-neo4j
    restart: unless-stopped
    ports:
      - "7474:7474"  # HTTP browser interface
      - "7687:7687"  # Bolt protocol
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["graph-data-science"]
      - NEO4J_dbms_security_procedures_unrestricted=gds.*
      - NEO4J_dbms_memory_heap_initial_size=512m
      - NEO4J_dbms_memory_heap_max_size=2G
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    deploy:
      resources:
        limits:
          memory: 2.5G
    networks:
      - autodocs-network

  # MongoDB Database
  mongo:
    image: mongo
    container_name: autodocs-mongo
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_DATABASE=autodocs
    volumes:
      - mongo_data:/data/db
      - mongo_config:/data/configdb
    deploy:
      resources:
        limits:
          memory: 1G
    networks:
      - autodocs-network

  # MongoDB Admin Interface
  mongo-express:
    image: mongo-express
    container_name: autodocs-mongo-express
    restart: unless-stopped
    ports:
      - "8081:8081"
    environment:
      - ME_CONFIG_MONGODB_SERVER=mongo
      - ME_CONFIG_BASICAUTH=false
      - ME_CONFIG_MONGODB_URL=mongodb://mongo:27017/autodocs
    depends_on:
      - mongo
    deploy:
      resources:
        limits:
          memory: 512M
    networks:
      - autodocs-network

  # Local LLM Server
  ollama:
    image: ollama/ollama
    container_name: autodocs-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0
    deploy:
      resources:
        limits:
          memory: 4G
    entrypoint: ["/bin/bash", "-c"]
    command: |
      "ollama serve &
      sleep 10
      ollama pull nomic-embed-text
      wait"
    networks:
      - autodocs-network

  # Message Queue
  rabbitmq:
    image: rabbitmq:4.1.2-management
    container_name: autodocs-rabbitmq
    restart: unless-stopped
    ports:
      - "5672:5672"   # AMQP protocol
      - "15672:15672" # Management UI
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    deploy:
      resources:
        limits:
          memory: 1G
    networks:
      - autodocs-network
    profiles:
      - full  # Optional service for advanced features
  # autodocs-backend:
  #   build:
  #     context: ./back-end
  #     dockerfile: Dockerfile
  #   container_name: autodocs-backend
  #   ports:
  #     - "8000:8000"
  #   volumes:
  #     - ./back-end/src:/app
  #   environment:
  #     - PYTHONPATH=/app
  #     - PYTHONUNBUFFERED=1
  #   env_file:
  #     - ./back-end/.env
  #   working_dir: /app
  #   command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
  #   networks:
  #     - autodocs-network

networks:
  autodocs-network:
    driver: bridge

volumes:
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  mongo_data:
    driver: local
  mongo_config:
    driver: local
  ollama_data:
    driver: local
  rabbitmq_data:
    driver: local
